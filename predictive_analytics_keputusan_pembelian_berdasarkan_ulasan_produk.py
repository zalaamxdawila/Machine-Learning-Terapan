# -*- coding: utf-8 -*-
"""Predictive Analytics Keputusan Pembelian Berdasarkan Ulasan Produk.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1a6IWvy4JcmGT04TUtxhr3Fa7rz_NlYql
"""

import pandas as pd
import numpy as np
import re
import string
import joblib
import nltk
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize
from nltk.stem import PorterStemmer
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.naive_bayes import MultinomialNB
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report
from flask import Flask, request, jsonify

# Download NLTK resources
nltk.download('stopwords')
nltk.download('punkt')

# Load dataset
df = pd.read_csv("Ulasan.csv")

def preprocess_text(text):
    text = text.lower()
    text = re.sub(f"[{string.punctuation}]", "", text)
    words = word_tokenize(text)
    words = [word for word in words if word not in stopwords.words("english")]
    stemmer = PorterStemmer()
    words = [stemmer.stem(word) for word in words]
    return " ".join(words)

# Preprocess dataset
df = df.dropna(subset=['reviews.text', 'reviews.rating'])
df['sentiment'] = df['reviews.rating'].apply(lambda x: 'positive' if x > 3 else 'negative')
df['cleaned_review'] = df['reviews.text'].apply(preprocess_text)

# Split dataset
X = df['cleaned_review']
y = df['sentiment']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# TF-IDF Vectorization
tfidf = TfidfVectorizer()
X_train_tfidf = tfidf.fit_transform(X_train)
X_test_tfidf = tfidf.transform(X_test)

# Train models
models = {
    "Logistic Regression": LogisticRegression(),
    "Naïve Bayes": MultinomialNB(),
    "Random Forest": RandomForestClassifier()
}

best_model = None
best_accuracy = 0

for name, model in models.items():
    model.fit(X_train_tfidf, y_train)
    y_pred = model.predict(X_test_tfidf)
    acc = accuracy_score(y_test, y_pred)
    print(f"{name} Accuracy: {acc:.4f}")
    print(classification_report(y_test, y_pred))

    if acc > best_accuracy:
        best_accuracy = acc
        best_model = model

import matplotlib.pyplot as plt
import seaborn as sns

# Visualisasi distribusi sentimen
plt.figure(figsize=(8, 5))
sns.countplot(x='sentiment', data=df, palette='viridis')
plt.title('Distribusi Sentimen (Positif vs Negatif)', fontsize=15)
plt.xlabel('Sentimen', fontsize=12)
plt.ylabel('Jumlah Ulasan', fontsize=12)
plt.show()

# Akurasi per model
accuracy_dict = {
    "Logistic Regression": accuracy_score(y_test, LogisticRegression().fit(X_train_tfidf, y_train).predict(X_test_tfidf)),
    "Naïve Bayes": accuracy_score(y_test, MultinomialNB().fit(X_train_tfidf, y_train).predict(X_test_tfidf)),
    "Random Forest": accuracy_score(y_test, RandomForestClassifier().fit(X_train_tfidf, y_train).predict(X_test_tfidf))
}

# Plot perbandingan akurasi model menggunakan pie chart
plt.figure(figsize=(8, 6))
plt.pie(accuracy_dict.values(), labels=accuracy_dict.keys(), autopct='%1.1f%%', startangle=90, colors=['#66b3ff', '#99ff99', '#ff6666'])
plt.title('Perbandingan Akurasi Model', fontsize=15)
plt.show()

from sklearn.metrics import confusion_matrix
import seaborn as sns

# Confusion matrix untuk model terbaik
y_pred_best_model = best_model.predict(X_test_tfidf)
cm = confusion_matrix(y_test, y_pred_best_model)

# Plot confusion matrix
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Negative', 'Positive'], yticklabels=['Negative', 'Positive'])
plt.title('Confusion Matrix - Best Model', fontsize=15)
plt.xlabel('Prediksi', fontsize=12)
plt.ylabel('Aktual', fontsize=12)
plt.show()

from sklearn.metrics import accuracy_score, classification_report, precision_score, recall_score, f1_score # Import precision_score, recall_score, and f1_score

# Menghitung Precision, Recall, F1-Score, dan Akurasi per model dalam persen
accuracy_dict = {}
precision_dict = {}
recall_dict = {}
f1_dict = {}

for name, model in models.items():
    model.fit(X_train_tfidf, y_train)
    y_pred = model.predict(X_test_tfidf)

    accuracy = accuracy_score(y_test, y_pred) * 100
    precision = precision_score(y_test, y_pred, pos_label='positive') * 100
    recall = recall_score(y_test, y_pred, pos_label='positive') * 100
    f1 = f1_score(y_test, y_pred, pos_label='positive') * 100

    accuracy_dict[name] = accuracy
    precision_dict[name] = precision
    recall_dict[name] = recall
    f1_dict[name] = f1

# Membuat plot secara horizontal (sejajar)
fig, axes = plt.subplots(1, 4, figsize=(24, 6))

# Plot Accuracy
sns.barplot(x=list(accuracy_dict.values()), y=list(accuracy_dict.keys()), ax=axes[0], palette='coolwarm')
axes[0].set_title('Akurasi per Model', fontsize=15)
axes[0].set_xlabel('Akurasi (%)', fontsize=12)
axes[0].set_ylabel('Model', fontsize=12)

# Plot Precision
sns.barplot(x=list(precision_dict.values()), y=list(precision_dict.keys()), ax=axes[1], palette='Blues')
axes[1].set_title('Precision per Model', fontsize=15)
axes[1].set_xlabel('Precision (%)', fontsize=12)
axes[1].set_ylabel('Model', fontsize=12)

# Plot Recall
sns.barplot(x=list(recall_dict.values()), y=list(recall_dict.keys()), ax=axes[2], palette='Greens')
axes[2].set_title('Recall per Model', fontsize=15)
axes[2].set_xlabel('Recall (%)', fontsize=12)
axes[2].set_ylabel('Model', fontsize=12)

# Plot F1-Score
sns.barplot(x=list(f1_dict.values()), y=list(f1_dict.keys()), ax=axes[3], palette='Oranges')
axes[3].set_title('F1-Score per Model', fontsize=15)
axes[3].set_xlabel('F1-Score (%)', fontsize=12)
axes[3].set_ylabel('Model', fontsize=12)

# Menampilkan plot
plt.tight_layout()
plt.show()

# Tabel persen metrik evaluasi dengan Akurasi
metrics_df = pd.DataFrame({
    "Akurasi (%)": list(accuracy_dict.values()),
    "Precision (%)": list(precision_dict.values()),
    "Recall (%)": list(recall_dict.values()),
    "F1-Score (%)": list(f1_dict.values())
}, index=list(models.keys()))

print("Tabel Perbandingan Metrik Evaluasi Model:")
print(metrics_df)

from wordcloud import WordCloud

# Gabungkan teks positif dan negatif
positive_reviews = " ".join(df[df['sentiment'] == 'positive']['cleaned_review'])
negative_reviews = " ".join(df[df['sentiment'] == 'negative']['cleaned_review'])

# Generate wordcloud untuk ulasan positif
plt.figure(figsize=(10, 6))
wordcloud_pos = WordCloud(width=800, height=400, background_color='white').generate(positive_reviews)
plt.imshow(wordcloud_pos, interpolation='bilinear')
plt.title('Wordcloud Ulasan Positif', fontsize=15)
plt.axis('off')
plt.show()

# Generate wordcloud untuk ulasan negatif
plt.figure(figsize=(10, 6))
wordcloud_neg = WordCloud(width=800, height=400, background_color='white').generate(negative_reviews)
plt.imshow(wordcloud_neg, interpolation='bilinear')
plt.title('Wordcloud Ulasan Negatif', fontsize=15)
plt.axis('off')
plt.show()

# Save best model and vectorizer
joblib.dump(best_model, "best_model.pkl")
joblib.dump(tfidf, "tfidf_vectorizer.pkl")

# Flask API
app = Flask(__name__)

@app.route('/predict', methods=['POST'])
def predict():
    data = request.get_json()
    review = data.get("review", "")

    if not review:
        return jsonify({"error": "Input tidak valid. Harap masukkan teks ulasan."}), 400

    processed_review = preprocess_text(review)
    transformed_review = tfidf.transform([processed_review])
    prediction = best_model.predict(transformed_review)[0]

    return jsonify({"review": review, "sentiment": prediction})

if __name__ == '__main__':
    app.run(debug=True)