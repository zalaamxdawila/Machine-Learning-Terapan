# -*- coding: utf-8 -*-
"""Predictive_Analytics_Keputusan_Pembelian_Berdasarkan_Ulasan_Produk.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1W4pQU0pLtpmgANsNoiqneio-jpGjt53c
"""

import pandas as pd
import numpy as np
import re
import string
import joblib
import nltk
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize
from nltk.stem import PorterStemmer
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.naive_bayes import MultinomialNB
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report
from flask import Flask, request, jsonify

# Download NLTK resources
nltk.download('stopwords')
nltk.download('punkt')

# Load dataset
df = pd.read_csv("Ulasan.csv")

def preprocess_text(text):
    text = text.lower()
    text = re.sub(f"[{string.punctuation}]", "", text)
    words = word_tokenize(text)
    words = [word for word in words if word not in stopwords.words("english")]
    stemmer = PorterStemmer()
    words = [stemmer.stem(word) for word in words]
    return " ".join(words)

"""Di baris pertama, saya memuat data dari file CSV "Ulasan.csv" ke dalam DataFrame `df`. Selanjutnya, saya melakukan *preprocessing* teks, dimulai dengan mengubah semua teks menjadi huruf kecil. Kemudian, saya menghapus tanda baca menggunakan *regular expression*. Setelah itu, teks dipecah menjadi kata-kata terpisah (*token*). Saya melanjutkan dengan menghapus *stopwords*, yaitu kata-kata umum yang tidak memiliki banyak makna. Langkah berikutnya adalah mengubah setiap kata ke bentuk dasarnya menggunakan metode *stemming*. Terakhir, token-token yang telah diproses digabungkan kembali menjadi string utuh. Teks yang telah diproses ini sekarang siap untuk dianalisis lebih lanjut.

"""

# Preprocess dataset
df = df.dropna(subset=['reviews.text', 'reviews.rating'])
df['sentiment'] = df['reviews.rating'].apply(lambda x: 'positive' if x > 3 else 'negative')
df['cleaned_review'] = df['reviews.text'].apply(preprocess_text)

"""Di baris pertama, saya melakukan pembersihan data dengan menghapus baris-baris yang memiliki nilai kosong pada kolom `reviews.text` atau `reviews.rating` menggunakan fungsi `dropna()`. Langkah ini krusial untuk memastikan data yang kita gunakan lengkap dan valid. Selanjutnya, di baris berikutnya, saya membuat kolom baru bernama `sentiment` yang akan menampung label sentimen dari setiap ulasan. Saya menggunakan fungsi `apply()` dengan *lambda expression* untuk menetapkan label "positive" jika ratingnya di atas 3, dan "negative" jika 3 atau kurang. Tujuannya adalah untuk mengelompokkan ulasan berdasarkan sentimennya. Terakhir, di baris akhir, saya membersihkan teks ulasan yang ada di kolom `reviews.text` dengan menerapkan fungsi `preprocess_text()`. Fungsi ini akan melakukan serangkaian *preprocessing* pada teks, seperti menghapus tanda baca dan *stopwords*, sehingga teks tersebut lebih siap untuk dianalisis. Hasilnya saya simpan di kolom baru bernama `cleaned_review`. Dengan demikian, data ulasan kita telah siap untuk tahap analisis selanjutnya.

"""

# Split dataset
X = df['cleaned_review']
y = df['sentiment']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

"""Langkah selanjutnya adalah mendefinisikan variabel yang akan digunakan dalam pelatihan model. Di baris ini, saya mengisi variabel `X` dengan data ulasan yang sudah dibersihkan, yang tersimpan di kolom `cleaned_review`. Data ini akan menjadi fitur atau masukan bagi model. Kemudian, variabel `y` diisi dengan label sentimen yang ada di kolom `sentiment`. Label ini akan menjadi target atau keluaran yang diharapkan dari model. Setelah variabel `X` dan `y` didefinisikan, saya menggunakan fungsi `train_test_split` untuk membagi dataset menjadi dua bagian: data pelatihan (`X_train` dan `y_train`) dan data pengujian (`X_test` dan `y_test`). Data pelatihan akan digunakan untuk melatih model, sementara data pengujian akan digunakan untuk menguji seberapa baik model tersebut bekerja pada data baru yang belum pernah dilihatnya. Dalam pembagian ini, saya menggunakan parameter `test_size=0.2`, yang berarti 20% dari total data akan dialokasikan untuk data pengujian, dan 80% sisanya untuk data pelatihan. Selain itu, saya juga menetapkan `random_state=42`. Parameter ini penting untuk memastikan bahwa pembagian data yang kita lakukan selalu sama setiap kali kode ini dijalankan. Dengan demikian, kita bisa mendapatkan hasil yang konsisten dan dapat dibandingkan.

"""

# TF-IDF Vectorization
tfidf = TfidfVectorizer()
X_train_tfidf = tfidf.fit_transform(X_train)
X_test_tfidf = tfidf.transform(X_test)

"""Di baris pertama, saya menginisialisasi sebuah objek `TfidfVectorizer`. Objek ini bertugas untuk mengubah teks ulasan menjadi representasi numerik yang bermakna, dengan menggunakan metode *Term Frequency-Inverse Document Frequency* (TF-IDF). TF-IDF adalah teknik yang umum digunakan dalam pemrosesan bahasa alami untuk mengukur seberapa penting sebuah kata dalam sebuah dokumen dibandingkan dengan keseluruhan kumpulan dokumen. Selanjutnya, di baris berikutnya, saya menggunakan metode `fit_transform` pada data pelatihan `X_train`. Metode ini tidak hanya mengubah teks dalam `X_train` menjadi matriks fitur TF-IDF, tetapi juga sekaligus mempelajari statistik TF-IDF dari data pelatihan tersebut. Statistik ini penting untuk digunakan pada data pengujian nanti. Terakhir, di baris akhir, saya menerapkan metode `transform` pada data pengujian `X_test`. Metode ini menggunakan statistik TF-IDF yang telah dipelajari sebelumnya dari data pelatihan untuk mengubah teks dalam `X_test` menjadi matriks fitur. Perlu diperhatikan bahwa kita hanya menggunakan `transform` pada data pengujian, dan bukan `fit_transform`, karena kita ingin memastikan bahwa representasi fitur untuk data pengujian konsisten dengan data pelatihan. Dengan kata lain, kita ingin menggunakan "kacamata" yang sama (statistik TF-IDF dari data pelatihan) untuk melihat data pengujian.

"""

# Train models
models = {
    "Logistic Regression": LogisticRegression(),
    "Naïve Bayes": MultinomialNB(),
    "Random Forest": RandomForestClassifier()
}

best_model = None
best_accuracy = 0

for name, model in models.items():
    model.fit(X_train_tfidf, y_train)
    y_pred = model.predict(X_test_tfidf)
    acc = accuracy_score(y_test, y_pred)
    print(f"{name} Accuracy: {acc:.4f}")
    print(classification_report(y_test, y_pred))

    if acc > best_accuracy:
        best_accuracy = acc
        best_model = model

"""Saya menginisialisasi tiga model *machine learning* yang berbeda untuk tugas klasifikasi sentimen, yaitu *Logistic Regression*, *Multinomial Naïve Bayes*, dan *Random Forest Classifier*. Ketiga model ini dipilih karena karakteristiknya yang berbeda dan cocok untuk menangani data teks. Selanjutnya, untuk setiap model, saya melakukan proses pelatihan dan evaluasi. Saya melatih model menggunakan metode `fit` dengan data *training* yang telah diubah menjadi fitur TF-IDF. Setelah model terlatih, saya melakukan prediksi sentimen pada data *testing* TF-IDF menggunakan metode `predict`. Untuk mengukur performa model, saya menghitung akurasi menggunakan fungsi `accuracy_score`. Selain akurasi, saya juga menampilkan laporan klasifikasi yang lebih detail menggunakan `classification_report`. Laporan ini mencakup metrik *precision*, *recall*, dan *F1-score* yang memberikan gambaran lebih komprehensif tentang kinerja model. Terakhir, setelah semua model dievaluasi, saya mencari model terbaik berdasarkan akurasi tertinggi. Model dengan akurasi terbaik ini disimpan sebagai `best_model`, dan nilai akurasi terbaik juga disimpan untuk perbandingan selanjutnya. Proses ini memastikan bahwa kita memilih model yang paling optimal untuk tugas klasifikasi sentimen ini.

"""

import matplotlib.pyplot as plt
import seaborn as sns

# Visualisasi distribusi sentimen
plt.figure(figsize=(8, 5))
sns.countplot(x='sentiment', data=df, palette='viridis')
plt.title('Distribusi Sentimen (Positif vs Negatif)', fontsize=15)
plt.xlabel('Sentimen', fontsize=12)
plt.ylabel('Jumlah Ulasan', fontsize=12)
plt.show()

"""Untuk memahami distribusi sentimen dalam dataset, saya menggunakan library `matplotlib.pyplot` dan `seaborn` untuk membuat visualisasi data. Pertama, saya menggunakan fungsi `sns.countplot` untuk membuat *count plot* yang menampilkan jumlah ulasan untuk setiap kategori sentimen, yaitu 'positive' dan 'negative'.  Untuk memberikan tampilan yang menarik, saya menggunakan palet warna 'viridis' melalui argumen `palette`.  Selanjutnya, saya menambahkan judul grafik menggunakan `plt.title`, serta label untuk sumbu x (kategori sentimen) dan sumbu y (jumlah ulasan) menggunakan `plt.xlabel` dan `plt.ylabel`.  Penambahan label ini bertujuan agar grafik mudah dipahami dan informatif. Terakhir, untuk menampilkan grafik yang telah dibuat, saya menggunakan fungsi `plt.show()`. Visualisasi ini sangat membantu dalam memahami bagaimana sentimen didistribusikan dalam dataset sebelum kita melanjutkan ke tahap analisis yang lebih lanjut.

"""

# Akurasi per model
accuracy_dict = {
    "Logistic Regression": accuracy_score(y_test, LogisticRegression().fit(X_train_tfidf, y_train).predict(X_test_tfidf)),
    "Naïve Bayes": accuracy_score(y_test, MultinomialNB().fit(X_train_tfidf, y_train).predict(X_test_tfidf)),
    "Random Forest": accuracy_score(y_test, RandomForestClassifier().fit(X_train_tfidf, y_train).predict(X_test_tfidf))
}

# Plot perbandingan akurasi model menggunakan pie chart
plt.figure(figsize=(8, 6))
plt.pie(accuracy_dict.values(), labels=accuracy_dict.keys(), autopct='%1.1f%%', startangle=90, colors=['#66b3ff', '#99ff99', '#ff6666'])
plt.title('Perbandingan Akurasi Model', fontsize=15)
plt.show()

"""TUntuk mengevaluasi performa model secara kuantitatif, saya menghitung akurasi dari masing-masing model yang telah dilatih.  Di baris pertama, saya melatih ulang ketiga model—*Logistic Regression*, *Naïve Bayes*, dan *Random Forest*—menggunakan data pelatihan yang telah diubah menjadi representasi TF-IDF.  Tujuannya adalah untuk memastikan bahwa perhitungan akurasi didasarkan pada model yang telah terlatih dengan baik. Selanjutnya, saya menggunakan fungsi `accuracy_score` untuk menghitung akurasi dari masing-masing model. Fungsi ini membandingkan hasil prediksi model dengan label sentimen yang sebenarnya pada data uji (`y_test`). Hasil akurasi dari setiap model kemudian disimpan dalam sebuah dictionary bernama `accuracy_dict`.  Setelah mendapatkan nilai akurasi untuk setiap model, saya membuat visualisasi perbandingan akurasi menggunakan *pie chart*.  Saya menggunakan `plt.pie` untuk membuat *pie chart*, dengan argumen `autopct='%1.1f%%'` untuk menampilkan persentase akurasi di setiap irisan *pie chart*.  Untuk tampilan yang lebih menarik, saya mengatur sudut awal diagram menggunakan `startangle=90` dan memberikan warna yang berbeda untuk setiap model menggunakan argumen `colors`. Terakhir, saya menambahkan judul pada *pie chart* menggunakan `plt.title` untuk memberikan konteks informasi yang jelas.  Visualisasi ini memudahkan kita untuk melihat dan membandingkan akurasi dari ketiga model secara sekilas.

"""

from sklearn.metrics import confusion_matrix
import seaborn as sns

# Confusion matrix untuk model terbaik
y_pred_best_model = best_model.predict(X_test_tfidf)
cm = confusion_matrix(y_test, y_pred_best_model)

# Plot confusion matrix
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Negative', 'Positive'], yticklabels=['Negative', 'Positive'])
plt.title('Confusion Matrix - Best Model', fontsize=15)
plt.xlabel('Prediksi', fontsize=12)
plt.ylabel('Aktual', fontsize=12)
plt.show()

"""Untuk menganalisis lebih dalam kinerja model terbaik, saya membuat *confusion matrix*. Pertama, saya menggunakan model terbaik (`best_model`) untuk memprediksi sentimen pada data uji TF-IDF (`X_test_tfidf`). Hasil prediksi ini kemudian dibandingkan dengan label sentimen aktual (`y_test`) menggunakan fungsi `confusion_matrix` untuk menghasilkan matriks kebingungan. Matriks ini memberikan informasi detail tentang berapa banyak prediksi yang benar dan salah untuk setiap kelas sentimen. Selanjutnya, saya memvisualisasikan *confusion matrix* ini menggunakan *heatmap* dari library `seaborn`.  Saya menggunakan `sns.heatmap` untuk menampilkan matriks sebagai *heatmap* dengan nilai numerik di setiap selnya (`annot=True`).  Format angka bulat (`fmt='d'`) digunakan agar tampilan lebih rapi.  Untuk estetika, saya memilih palet warna biru (`cmap='Blues'`).  Agar visualisasi lebih mudah dipahami, saya menambahkan label pada sumbu x dan y menggunakan `xticklabels` dan `yticklabels` dengan nilai 'Negative' dan 'Positive', serta label sumbu `plt.xlabel('Prediksi')` dan `plt.ylabel('Aktual')` untuk memperjelas arah perbandingan.  Dengan visualisasi *confusion matrix* ini, kita dapat melihat secara detail kinerja model dalam mengklasifikasikan sentimen, termasuk jenis kesalahan yang mungkin dilakukan model.

"""

from sklearn.metrics import accuracy_score, classification_report, precision_score, recall_score, f1_score # Import precision_score, recall_score, and f1_score

# Menghitung Precision, Recall, F1-Score, dan Akurasi per model dalam persen
accuracy_dict = {}
precision_dict = {}
recall_dict = {}
f1_dict = {}

for name, model in models.items():
    model.fit(X_train_tfidf, y_train)
    y_pred = model.predict(X_test_tfidf)

    accuracy = accuracy_score(y_test, y_pred) * 100
    precision = precision_score(y_test, y_pred, pos_label='positive') * 100
    recall = recall_score(y_test, y_pred, pos_label='positive') * 100
    f1 = f1_score(y_test, y_pred, pos_label='positive') * 100

    accuracy_dict[name] = accuracy
    precision_dict[name] = precision
    recall_dict[name] = recall
    f1_dict[name] = f1

# Membuat plot secara horizontal (sejajar)
fig, axes = plt.subplots(1, 4, figsize=(24, 6))

# Plot Accuracy
sns.barplot(x=list(accuracy_dict.values()), y=list(accuracy_dict.keys()), ax=axes[0], palette='coolwarm')
axes[0].set_title('Akurasi per Model', fontsize=15)
axes[0].set_xlabel('Akurasi (%)', fontsize=12)
axes[0].set_ylabel('Model', fontsize=12)

# Plot Precision
sns.barplot(x=list(precision_dict.values()), y=list(precision_dict.keys()), ax=axes[1], palette='Blues')
axes[1].set_title('Precision per Model', fontsize=15)
axes[1].set_xlabel('Precision (%)', fontsize=12)
axes[1].set_ylabel('Model', fontsize=12)

# Plot Recall
sns.barplot(x=list(recall_dict.values()), y=list(recall_dict.keys()), ax=axes[2], palette='Greens')
axes[2].set_title('Recall per Model', fontsize=15)
axes[2].set_xlabel('Recall (%)', fontsize=12)
axes[2].set_ylabel('Model', fontsize=12)

# Plot F1-Score
sns.barplot(x=list(f1_dict.values()), y=list(f1_dict.keys()), ax=axes[3], palette='Oranges')
axes[3].set_title('F1-Score per Model', fontsize=15)
axes[3].set_xlabel('F1-Score (%)', fontsize=12)
axes[3].set_ylabel('Model', fontsize=12)

# Menampilkan plot
plt.tight_layout()
plt.show()

# Tabel persen metrik evaluasi dengan Akurasi
metrics_df = pd.DataFrame({
    "Akurasi (%)": list(accuracy_dict.values()),
    "Precision (%)": list(precision_dict.values()),
    "Recall (%)": list(recall_dict.values()),
    "F1-Score (%)": list(f1_dict.values())
}, index=list(models.keys()))

print("Tabel Perbandingan Metrik Evaluasi Model:")
print(metrics_df)

"""Setelah mendapatkan *confusion matrix*, saya menghitung metrik evaluasi yang lebih komprehensif, yaitu akurasi (*accuracy*), presisi (*precision*), *recall*, dan *F1-score*.  Metrik-metrik ini dihitung untuk memberikan gambaran yang lebih lengkap tentang performa model.  Untuk memudahkan interpretasi, hasil metrik dikalikan 100 agar ditampilkan dalam bentuk persentase.  Saya juga menentukan `pos_label='positive'` agar perhitungan metrik difokuskan pada kelas 'positive', yang biasanya menjadi perhatian utama dalam analisis sentimen.  Selanjutnya, untuk memudahkan perbandingan antar model, saya membuat visualisasi grafis.  Saya membuat empat *subplot* horizontal, masing-masing untuk akurasi, presisi, *recall*, dan *F1-score. Setiap *subplot* menampilkan barplot dari library `seaborn` yang membandingkan nilai metrik untuk ketiga model.  Untuk membedakan setiap metrik, saya menggunakan palet warna yang berbeda, seperti `coolwarm`, `Blues`, `Greens`, dan `Oranges`.  Terakhir, saya menampilkan tabel evaluasi yang berisi ringkasan numerik dari semua metrik untuk setiap model. Tabel `metrics_df` ini menyajikan informasi dalam format yang mudah dibaca dan memungkinkan perbandingan cepat antar model.  Dengan visualisasi dan tabel ini, kita dapat dengan mudah memilih model terbaik berdasarkan metrik yang paling relevan dengan tujuan analisis kita.

"""

from wordcloud import WordCloud

# Gabungkan teks positif dan negatif
positive_reviews = " ".join(df[df['sentiment'] == 'positive']['cleaned_review'])
negative_reviews = " ".join(df[df['sentiment'] == 'negative']['cleaned_review'])

# Generate wordcloud untuk ulasan positif
plt.figure(figsize=(10, 6))
wordcloud_pos = WordCloud(width=800, height=400, background_color='white').generate(positive_reviews)
plt.imshow(wordcloud_pos, interpolation='bilinear')
plt.title('Wordcloud Ulasan Positif', fontsize=15)
plt.axis('off')
plt.show()

# Generate wordcloud untuk ulasan negatif
plt.figure(figsize=(10, 6))
wordcloud_neg = WordCloud(width=800, height=400, background_color='white').generate(negative_reviews)
plt.imshow(wordcloud_neg, interpolation='bilinear')
plt.title('Wordcloud Ulasan Negatif', fontsize=15)
plt.axis('off')
plt.show()

"""### 1. Menggabungkan Teks Ulasan

- **`df[df['sentiment'] == 'positive']`**: Baris ini memfilter DataFrame (`df`) untuk memilih hanya ulasan yang memiliki sentimen positif. Filter ini bekerja dengan memeriksa nilai pada kolom `sentiment` dan memilih baris yang nilainya 'positive'.

- **`df['cleaned_review']`**: Bagian ini memilih kolom `cleaned_review` dari DataFrame yang telah difilter. Kolom ini diasumsikan berisi teks ulasan yang sudah dibersihkan atau dipreproses, seperti penghapusan tanda baca, *stopwords*, dan stemming. Teks yang sudah dipreproses ini lebih cocok untuk dianalisis karena kata-kata yang tidak relevan sudah dihilangkan.

- **`" ".join(...)`**: Fungsi `join` digunakan untuk menggabungkan seluruh teks ulasan yang telah dipilih menjadi satu string besar. String ini akan menjadi input bagi WordCloud. Penggabungan ini penting karena WordCloud bekerja dengan menganalisis frekuensi kata dalam satu teks yang besar.

### 2. Membuat WordCloud untuk Ulasan Positif

- **`WordCloud(...).generate(positive_reviews)`**: Baris ini adalah inti dari pembuatan WordCloud. Objek `WordCloud` dibuat dengan beberapa parameter (yang akan dijelaskan di bawah), dan metode `generate` dipanggil dengan string `positive_reviews` sebagai input. Metode ini akan menghitung frekuensi kata dalam string dan menghasilkan gambar WordCloud.

- **`background_color='white'`**: Parameter ini mengatur warna latar belakang WordCloud menjadi putih. Latar belakang putih biasanya lebih disukai karena membuat kata-kata lebih mudah dibaca.

- **`plt.imshow(wordcloud_pos, interpolation='bilinear')`**: Fungsi `imshow` dari `matplotlib.pyplot` digunakan untuk menampilkan gambar WordCloud. Parameter `interpolation='bilinear'` digunakan untuk menghaluskan gambar.

- **`plt.axis('off')`**: Baris ini menghilangkan sumbu x dan y dari plot. Sumbu biasanya tidak diperlukan dalam visualisasi WordCloud, sehingga menghilangkannya membuat tampilan lebih bersih.

- **`plt.title(...)`**: Fungsi `title` digunakan untuk menambahkan judul pada plot. Judul ini membantu membedakan WordCloud untuk ulasan positif dan negatif.

### 3. Membuat WordCloud untuk Ulasan Negatif

- Langkah-langkah untuk membuat WordCloud untuk ulasan negatif pada dasarnya sama dengan ulasan positif. Perbedaannya hanya terletak pada data yang digunakan, yaitu `negative_reviews`.

### 4. Fungsi WordCloud dalam Analisis Sentimen

- **Mengidentifikasi Kata-Kata Dominan**: WordCloud bekerja dengan menampilkan kata-kata yang paling sering muncul dalam teks dengan ukuran yang lebih besar. Semakin sering sebuah kata muncul, semakin besar pula ukurannya dalam WordCloud. Hal ini memudahkan kita untuk melihat kata-kata mana yang paling dominan dalam ulasan.

- **Membantu Pemasaran & Peningkatan Produk**:
    - **Ulasan Positif**: Kata-kata yang dominan dalam ulasan positif dapat diidentifikasi sebagai *Unique Selling Points* (USP) atau keunggulan produk yang perlu ditonjolkan dalam pemasaran.
    - **Ulasan Negatif**: Kata-kata yang dominan dalam ulasan negatif dapat menjadi masukan berharga untuk perbaikan produk. Misalnya, jika kata "rusak" atau "lambat" sering muncul dalam ulasan negatif, ini menunjukkan masalah yang perlu segera ditangani.

- **Visualisasi yang Mudah Dipahami**: WordCloud menyajikan informasi secara visual, sehingga lebih mudah dan cepat dipahami daripada membaca daftar kata-kata. Visualisasi ini sangat membantu dalam analisis sentimen karena kita dapat dengan cepat melihat tema atau topik apa yang paling banyak dibicarakan oleh pelanggan.

## Tambahan

Beberapa parameter penting lainnya yang sering digunakan dalam WordCloud antara lain:

- **`max_words`**: Mengatur jumlah maksimum kata yang ditampilkan dalam WordCloud.
- **`stopwords`**: Daftar kata-kata yang ingin dihilangkan dari WordCloud (misalnya, kata-kata umum seperti "yang", "dan", "di").
- **`colormap`**: Mengatur warna WordCloud.

Dengan memahami kode dan penjelasan di atas, Anda dapat memanfaatkan WordCloud untuk menganalisis sentimen ulasan produk secara efektif dan mendapatkan wawasan berharga untuk pengembangan bisnis.

"""

# Save best model and vectorizer
joblib.dump(best_model, "best_model.pkl")
joblib.dump(tfidf, "tfidf_vectorizer.pkl")

"""Di baris ini, saya melakukan penyimpanan model *machine learning* terbaik yang telah saya latih, yang saya beri nama `best_model`, ke dalam sebuah file dengan nama `best_model.pkl`. Saya menggunakan fungsi `joblib.dump()` untuk melakukan penyimpanan ini karena library `joblib` memang dirancang khusus untuk menangani penyimpanan objek Python yang besar dan kompleks, seperti model *machine learning*.  Selanjutnya, di baris berikutnya, saya juga menyimpan objek *vectorizer* TF-IDF yang telah saya gunakan untuk mengubah teks menjadi fitur numerik.  *Vectorizer* ini saya simpan ke dalam file bernama `tfidf_vectorizer.pkl` menggunakan fungsi yang sama, `joblib.dump()`. Penyimpanan *vectorizer* ini sama pentingnya dengan penyimpanan model, karena kita membutuhkannya untuk melakukan transformasi pada data teks baru yang akan kita gunakan untuk prediksi di kemudian hari. Dengan menyimpan kedua objek ini, saya memastikan bahwa saya dapat dengan mudah menggunakan kembali model dan *vectorizer* ini tanpa perlu melatihnya dari awal, sehingga menghemat waktu dan sumber daya yang signifikan.

"""

# Flask API
app = Flask(__name__)

@app.route('/predict', methods=['POST'])
def predict():
    data = request.get_json()
    review = data.get("review", "")

    if not review:
        return jsonify({"error": "Input tidak valid. Harap masukkan teks ulasan."}), 400

    processed_review = preprocess_text(review)
    transformed_review = tfidf.transform([processed_review])
    prediction = best_model.predict(transformed_review)[0]

    return jsonify({"review": review, "sentiment": prediction})

if __name__ == '__main__':
    app.run(debug=True)

"""Di baris pertama, saya membuat sebuah aplikasi Flask baru dan menyimpannya dalam variabel `app`.  Selanjutnya, di baris berikutnya, saya mendekorasi fungsi `predict()` dengan `@app.route('/predict', methods=['POST'])`, yang artinya saya mendefinisikan *endpoint* `/predict` yang hanya menerima *request* dengan metode POST.  Di dalam fungsi `predict()`, di baris ini saya mengambil data yang dikirim dalam format JSON dari *request* menggunakan `request.get_json()`. Data ini diharapkan berisi teks ulasan. Kemudian, di baris selanjutnya, saya mengambil teks ulasan dari data JSON menggunakan `data.get("review", "")`.  Jika tidak ada ulasan yang diberikan, saya menggunakan string kosong sebagai nilai *default*.  Lalu, di baris berikutnya, saya memeriksa apakah teks ulasan kosong. Jika ya, saya mengembalikan *response* JSON yang berisi pesan kesalahan dan *kode status* 400. Jika teks ulasan tidak kosong, di baris selanjutnya saya memanggil fungsi `preprocess_text()` untuk membersihkan dan memproses teks ulasan tersebut.  Teks yang sudah diproses ini kemudian diubah menjadi representasi numerik menggunakan *vectorizer* TF-IDF yang telah saya latih sebelumnya, di baris ini.  Setelah teks diubah menjadi representasi numerik, di baris ini saya menggunakan model terbaik (`best_model`) untuk memprediksi sentimen dari teks ulasan tersebut. Hasil prediksi kemudian dikembalikan dalam format JSON yang berisi teks ulasan asli dan hasil prediksi sentimen, di baris terakhir fungsi ini. Terakhir, di baris ini saya menjalankan aplikasi Flask dengan *mode debug* aktif.

"""